{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle,regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in Tweepy data, and turning into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"search_output-2016-04-16.bin\") as tweet_file:\n",
    "    results = []\n",
    "    while not tweet_file.closed:\n",
    "        try: \n",
    "            results += [pickle.load(tweet_file)]\n",
    "        \n",
    "        except EOFError: tweet_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exclusion_list = [\"http\"]\n",
    "table = string.maketrans(\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for r in results[:]:\n",
    "    temp_words = r.split(\" \")\n",
    "    words = []\n",
    "    for tw in temp_words: words += tw.split(\"\\n\") \n",
    "    for w in words:\n",
    "        temp_word = regex.sub(ur\"\\p{P}+\", \"\", w.lower())\n",
    "        if not any([e in temp_word for e in exclusion_list ]) or temp_word is not u'':\n",
    "            if temp_word not in word_dict: word_dict[temp_word] = 0\n",
    "            word_dict[temp_word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting and reducing the word list.\n",
    "\n",
    "Reducing in this context means removing any words that are substrings of other words, and removing the unique entry and adding the substring word's count to the superstring's entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reducing down the word list\n",
    "word_list = sorted(word_dict.items(),key=lambda x:x[0])\n",
    "new_word_list = []\n",
    "word_stack = 0\n",
    "for i,w in enumerate(word_list[:-1]):\n",
    "    if w[0] not in word_list[i+1][0]: \n",
    "        new_word_list += [(w[0],w[1]+word_stack)]\n",
    "        word_stack = 0\n",
    "    else: \n",
    "        word_stack += w[1]\n",
    "        \n",
    "#sorting by number of times used\n",
    "word_list = sorted(new_word_list,key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'managed', 53),\n",
       " (u'needed', 53),\n",
       " (u'weekendbreakfast', 53),\n",
       " (u'mostly', 54),\n",
       " (u'online', 54),\n",
       " (u'shouldnt', 54),\n",
       " (u'thando', 54),\n",
       " (u'werent', 54),\n",
       " (u'africanamericans', 55),\n",
       " (u'against', 55),\n",
       " (u'southafrican', 55),\n",
       " (u'videos', 56),\n",
       " (u'when', 56),\n",
       " (u'wouldnt', 56),\n",
       " (u'leadership', 57),\n",
       " (u'manifestoites', 57),\n",
       " (u'mustafizurs', 57),\n",
       " (u'liveaction', 59),\n",
       " (u'theironmaidens', 59),\n",
       " (u'sabcnewslive', 60),\n",
       " (u'takeaways', 60),\n",
       " (u'launched', 61),\n",
       " (u'soaking', 63),\n",
       " (u'trumps', 63),\n",
       " (u'viable', 63),\n",
       " (u'oneil', 64),\n",
       " (u'backers', 66),\n",
       " (u'getafe', 66),\n",
       " (u'theres', 67),\n",
       " (u'doable', 68),\n",
       " (u'if', 68),\n",
       " (u'liked', 68),\n",
       " (u'whod', 68),\n",
       " (u'justicemalala', 69),\n",
       " (u'japanearthquake', 70),\n",
       " (u'popefrancis', 70),\n",
       " (u'theyd', 74),\n",
       " (u'herebastards', 75),\n",
       " (u'todays', 75),\n",
       " (u'allah', 76),\n",
       " (u'headache', 77),\n",
       " (u'timed', 77),\n",
       " (u'years', 77),\n",
       " (u'upcoming', 78),\n",
       " (u'myanc', 80),\n",
       " (u'nowhere', 82),\n",
       " (u'canadas', 83),\n",
       " (u'overalls', 85),\n",
       " (u'wasangamayhem', 89),\n",
       " (u'nobody', 90),\n",
       " (u'ourselves', 94),\n",
       " (u'why', 98),\n",
       " (u'butler', 101),\n",
       " (u'outbound', 101),\n",
       " (u'whatever', 102),\n",
       " (u'usage', 103),\n",
       " (u'amp', 104),\n",
       " (u'more', 104),\n",
       " (u'historically', 106),\n",
       " (u'presidential', 106),\n",
       " (u'afternoon', 110),\n",
       " (u'anaesthetics', 119),\n",
       " (u'iamalanwalker', 121),\n",
       " (u'newcastle', 130),\n",
       " (u'notch', 137),\n",
       " (u'about', 138),\n",
       " (u'however', 142),\n",
       " (u'itself', 145),\n",
       " (u'youre', 145),\n",
       " (u'peoples', 148),\n",
       " (u'byelection', 153),\n",
       " (u'says', 155),\n",
       " (u'havens', 164),\n",
       " (u'hashtagging', 166),\n",
       " (u'willard', 177),\n",
       " (u'weakest', 178),\n",
       " (u'asap', 185),\n",
       " (u'zumas', 185),\n",
       " (u'beach', 188),\n",
       " (u'italian', 195),\n",
       " (u'fromtga', 200),\n",
       " (u'thato', 202),\n",
       " (u'anchovies', 213),\n",
       " (u'|', 213),\n",
       " (u'this', 220),\n",
       " (u'atakubariki', 234),\n",
       " (u'within', 246),\n",
       " (u'ancmanifestolaunch', 251),\n",
       " (u'areas', 264),\n",
       " (u'youd', 272),\n",
       " (u'oncebiggest', 459),\n",
       " (u'isabelhardman', 478),\n",
       " (u'foray', 487),\n",
       " (u'andbizarre', 504),\n",
       " (u'$100000', 639),\n",
       " (u'aaaarrrrggghhhh', 739),\n",
       " (u'inaugural', 792),\n",
       " (u'offences', 890),\n",
       " (u'toasts', 1186),\n",
       " (u'theaters', 1655)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
